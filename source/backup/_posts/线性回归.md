---
title: 线性回归
date: 2022-01-24 16:01:48
tags:
categories:
---



# 最小二乘法

least sqaure method

顾名思义，找到合适的参数，使得取到minimum of the square

![image-20220124160550012](https://gitee.com/simple_one1/pic/raw/master/image-20220124160550012.png)



那怎么找到那个参数呢

梯度下降 - Grandient Descend



# 梯度下降法

Grandient Descend

最快取得函数最小值的一种方法（即解决上面 “使得sum of square 最小” 的问题）

![image-20220124162232558](https://gitee.com/simple_one1/pic/raw/master/image-20220124162232558.png)

Grandient：斜率

当前位置最快下降的位置，是沿着当前点的切线的方向

实现：

```python
import matplotlib.pyplot as plt
import numpy as np

def f(x):
    return x**2

def gradient_descend():
    times = 20
    alpha = 0.1
    x0 = 10
    y0 = f(x0)
    x = np.linspace(-10,10)
    plt.figure()
    plt.xlabel('x')
    plt.ylabel('y')
    plt.plot(x,f(x))

    
    for i in range(times):
        dot_x = x0
        dot_y = y0
        print("第%d次迭代：x=%f,y=%f"%(i+1, x0, y0))
        
        # 2x为y=x^2的导数
        x0 = x0 - alpha*2*x0
        y0 = f(x0)
        
        plt.plot([dot_x,x0],[dot_y,y0],'go')
    
    plt.show()

if __name__ == "__main__":
    gradient_descend()
```

![image-20220124170157518](https://gitee.com/simple_one1/pic/raw/master/image-20220124170157518.png)![image-20220124170210590](https://gitee.com/simple_one1/pic/raw/master/image-20220124170210590.png)





# 线性回归实现

